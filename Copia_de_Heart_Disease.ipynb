{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyOKTS5bWr6T"
      },
      "source": [
        "## IA PROYECT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8KygRlLYxL5"
      },
      "source": [
        "# 1. Implementamos librerias, configuración del Entorno y Carga de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR9vBooNY0K5",
        "outputId": "b3244ea1-10f0-4fbc-faec-f1170a61ad26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.50.0)\n",
            "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# 1. Instalar librería de interpretabilidad SHAP\n",
        "!pip install shap\n",
        "\n",
        "# 2. Importar módulos esenciales\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "\n",
        "# Módulos de Scikit-learn\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score\n",
        "\n",
        "# Módulo SHAP\n",
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG4KIzouaZYx",
        "outputId": "0233db1b-ccd8-439a-8593-23e11e611a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ÉXITO: Dataset cargado correctamente. Dimensiones: (920, 16)\n"
          ]
        }
      ],
      "source": [
        "# 3. Montar Google Drive y Cargar el Dataset\n",
        "# **¡ATENCIÓN! REVISA Y PEGA LA RUTA CORRECTA DE TU ARCHIVO EN DRIVE**\n",
        "try:\n",
        "    drive.mount('/content/drive')\n",
        "    ruta_dataset = '/content/drive/MyDrive/IAProyecto/heart_disease_uci.csv' ## DEBE SER CAMBIADO SEGÚN LA RUTA DONDE FUE AGREGADA EL .CSV!!!\n",
        "    df = pd.read_csv(ruta_dataset)\n",
        "    print(\"ÉXITO: Dataset cargado correctamente. Dimensiones:\", df.shape)\n",
        "except FileNotFoundError:\n",
        "    print(\"ERROR FATAL: Archivo no encontrado. Revisa la ruta en 'ruta_dataset'.\")\n",
        "except Exception as e:\n",
        "    print(f\"ERROR AL CARGAR: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNkKID0kbgRA"
      },
      "source": [
        "## 2. Procesamiento robusto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VfygHthbk3Y",
        "outputId": "74d0e0cb-5742-42b3-9c47-3f3fe7c63a20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4173791650.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True) # Moda para categóricos\n",
            "/tmp/ipython-input-4173791650.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True) # Mediana para numéricos\n",
            "/tmp/ipython-input-4173791650.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True) # Moda para categóricos\n"
          ]
        }
      ],
      "source": [
        "# 1. Reemplazar valores erróneos ('?') por NaN y eliminar columnas irrelevantes\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.drop(columns=['id', 'dataset'], inplace=True)\n",
        "\n",
        "# 2. Identificar columnas con posibles errores de tipo (como 'ca' y 'thal' que pueden ser object/string por los '?' )\n",
        "for col in ['ca', 'thalch', 'oldpeak', 'trestbps', 'chol']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce') # Forzar a numérico, convirtiendo errores a NaN\n",
        "\n",
        "# 3. Imputación de nulos\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == object:\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True) # Moda para categóricos\n",
        "    elif df[col].isnull().any():\n",
        "        df[col].fillna(df[col].median(), inplace=True) # Mediana para numéricos\n",
        "\n",
        "# 4. Conversión de Target a Binario y Codificación\n",
        "df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
        "df.drop(columns=['num'], inplace=True)\n",
        "\n",
        "# 5. Codificación One-Hot\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "# 6. Definición X e Y\n",
        "y = df['target']\n",
        "X = df.drop(columns=['target'])\n",
        "feature_names = X.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoqBv1VadTUY"
      },
      "source": [
        "## 3. División, Estandarización y preparación final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93hegZ8qchrQ",
        "outputId": "cc2ac8d8-a7cd-480a-b261-3d0f87e7c59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paso 3 completado. Los datos están listos y estandarizados.\n"
          ]
        }
      ],
      "source": [
        "# 1. División (70% Entrenamiento, 30% Prueba)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. Estandarización de Features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convertir de vuelta a DataFrame (necesario para SHAP)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
        "\n",
        "print(\"Paso 3 completado. Los datos están listos y estandarizados.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwf7wp84dbqe"
      },
      "source": [
        "## 4. Entrenamiento y Evaluación de Modelos ML (Random Forest/SVC)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8k_g7Sucxce",
        "outputId": "99281402-5483-4d82-8526-b0ea55d6dbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Random Forest (ML) Resultados ---\n",
            "Accuracy: 0.8333\n",
            "Sensibilidad (Recall): 0.8562\n",
            "AUC: 0.8984\n",
            "\n",
            "--- SVC (ML) Resultados ---\n",
            "AUC: 0.9091\n"
          ]
        }
      ],
      "source": [
        "# 1. Inicializar y Entrenar Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 2. Evaluación Random Forest\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "y_prob_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(f\"\\n--- Random Forest (ML) Resultados ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"Sensibilidad (Recall): {recall_score(y_test, y_pred_rf):.4f}\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_prob_rf):.4f}\")\n",
        "\n",
        "# 3. Entrenamiento y Evaluación SVM (Ejemplo de otro modelo requerido)\n",
        "svc_model = SVC(kernel='rbf', probability=True, random_state=42)\n",
        "svc_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_prob_svc = svc_model.predict_proba(X_test_scaled)[:, 1]\n",
        "print(f\"\\n--- SVC (ML) Resultados ---\")\n",
        "print(f\"AUC: {roc_auc_score(y_test, y_prob_svc):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgge79KydeZu"
      },
      "source": [
        "## 5. Implementación de Modelo DL (Red Neuronal Profunda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTp2jA2_dDd6",
        "outputId": "12b5a021-3f2a-4f40-b974-d1be9f926b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Deep Learning (DL) Resultados ---\n",
            "Accuracy: 0.8188\n"
          ]
        }
      ],
      "source": [
        "# 1. Definición de la Arquitectura DL\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "\n",
        "dl_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 2. Compilación y Entrenamiento\n",
        "dl_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "dl_model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test_scaled, y_test),\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# 3. Evaluación final\n",
        "loss_dl, accuracy_dl = dl_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"\\n--- Deep Learning (DL) Resultados ---\")\n",
        "print(f\"Accuracy: {accuracy_dl:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cE5iCtpd2h-"
      },
      "source": [
        "## 6. Análisis de Interpretabilidad (SHAP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CweaK-HnVlAT",
        "outputId": "acf9cdaa-a8d3-4963-f850-5581d2f2980f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Análisis SHAP para Justificación Clínica ---\n",
            "El modelo está listo para generar gráficos de justificación\n"
          ]
        }
      ],
      "source": [
        "# 1. Seleccionar el modelo de mejor desempeño (Usaremos Random Forest como ejemplo)\n",
        "best_model = rf_model\n",
        "\n",
        "# 2. Crear el objeto Explainer\n",
        "# Nota: Si usas DL, el explainer cambia (shap.KernelExplainer o DeepExplainer)\n",
        "explainer = shap.TreeExplainer(best_model)\n",
        "\n",
        "# 3. Calcular valores SHAP (para la clase 'Enfermo' = 1)\n",
        "shap_values = explainer.shap_values(X_test_scaled)\n",
        "\n",
        "print(\"\\n--- Análisis SHAP para Justificación Clínica ---\")\n",
        "print(\"El modelo está listo para generar gráficos de justificación\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKLHC6zo5Xxe",
        "outputId": "de027b39-b5cf-47d3-b0a2-3b6cd4b72e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluando el rendimiento de los modelos...\n",
            "\n",
            "--- TABLA DE RESULTADOS COMPARATIVOS (ENTRENAMIENTO VS. PRUEBA) ---\n",
            "| Métrica                     | RF en Entrenamiento   | RF en Prueba   | Red Neuronal en Entrenamiento   | Red Neuronal en Prueba   |\n",
            "|:----------------------------|:----------------------|:---------------|:--------------------------------|:-------------------------|\n",
            "| Precisión (Accuracy)        | 100.00%               | 83.33%         | 96.27%                          | 81.88%                   |\n",
            "| Sensibilidad (Recall)       | 100.00%               | 85.62%         | 96.63%                          | 86.27%                   |\n",
            "| Especificidad (Specificity) | 100.00%               | 80.49%         | 95.83%                          | 76.42%                   |\n",
            "| AUC                         | 1.000                 | 0.898          | 0.995                           | 0.883                    |\n"
          ]
        }
      ],
      "source": [
        "# Importar las librerías necesarias para las métricas\n",
        "from sklearn.metrics import accuracy_score, recall_score, roc_auc_score, confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Función para calcular todas las métricas requeridas\n",
        "def get_all_metrics(model, X_data, y_data, model_type='ML', threshold=0.5):\n",
        "    \"\"\"\n",
        "    Calcula un conjunto completo de métricas para un modelo y un conjunto de datos.\n",
        "    \"\"\"\n",
        "    # Predicciones de clase (0 o 1)\n",
        "    if model_type == 'ML':\n",
        "        y_pred = model.predict(X_data)\n",
        "        y_prob = model.predict_proba(X_data)[:, 1]  # Probabilidades de la clase positiva\n",
        "    else:  # Modelo de Deep Learning (TensorFlow/Keras)\n",
        "        y_prob = model.predict(X_data, verbose=0).flatten()\n",
        "        y_pred = (y_prob > threshold).astype(int)  # Ajustar umbral de decisión\n",
        "\n",
        "    # Cálculo de métricas\n",
        "    accuracy = accuracy_score(y_data, y_pred)\n",
        "    recall = recall_score(y_data, y_pred, average='binary')  # Para clasificación binaria\n",
        "    auc = roc_auc_score(y_data, y_prob)  # AUC para clasificación binaria\n",
        "\n",
        "    # Para la Especificidad, necesitamos la matriz de confusión\n",
        "    tn, fp, fn, tp = confusion_matrix(y_data, y_pred).ravel()\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "    # Devolver resultados formateados para la tabla\n",
        "    return [f\"{accuracy*100:.2f}%\", f\"{recall*100:.2f}%\", f\"{specificity*100:.2f}%\", f\"{auc:.3f}\"]\n",
        "\n",
        "# --- OBTENCIÓN DE MÉTRICAS COMPARATIVAS ---\n",
        "# Asegúrate de que los modelos 'rf_model' y 'dl_model' ya han sido entrenados\n",
        "# y que los datos X_train_scaled, y_train, X_test_scaled, y_test están disponibles.\n",
        "\n",
        "print(\"Evaluando el rendimiento de los modelos...\")\n",
        "\n",
        "# 2. Evaluación en el CONJUNTO DE PRUEBA (datos no vistos)\n",
        "rf_test_results = get_all_metrics(rf_model, X_test_scaled, y_test, model_type='ML')\n",
        "dl_test_results = get_all_metrics(dl_model, X_test_scaled, y_test, model_type='DL')\n",
        "\n",
        "# 3. Evaluación en el CONJUNTO DE ENTRENAMIENTO (para detectar sobreajuste)\n",
        "rf_train_results = get_all_metrics(rf_model, X_train_scaled, y_train, model_type='ML')\n",
        "dl_train_results = get_all_metrics(dl_model, X_train_scaled, y_train, model_type='DL')\n",
        "\n",
        "# --- CREACIÓN DE LA TABLA COMPARATIVA FINAL ---\n",
        "\n",
        "# 4. Organizar los datos en un diccionario\n",
        "final_data = {\n",
        "    'Métrica': ['Precisión (Accuracy)', 'Sensibilidad (Recall)', 'Especificidad (Specificity)', 'AUC'],\n",
        "    'RF en Entrenamiento': rf_train_results,\n",
        "    'RF en Prueba': rf_test_results,\n",
        "    'Red Neuronal en Entrenamiento': dl_train_results,\n",
        "    'Red Neuronal en Prueba': dl_test_results\n",
        "}\n",
        "\n",
        "# 5. Crear y mostrar el DataFrame en formato Markdown\n",
        "df_final_results = pd.DataFrame(final_data)\n",
        "\n",
        "print(\"\\n--- TABLA DE RESULTADOS COMPARATIVOS (ENTRENAMIENTO VS. PRUEBA) ---\")\n",
        "print(df_final_results.to_markdown(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj98S3rid3jF"
      },
      "source": [
        "EVALUACIÓN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqB8kRPKXTxc",
        "outputId": "692e5ad2-9e4b-4aab-dc09-17583c43a9a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Función 'calculate_metrics' definida.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, confusion_matrix\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"Calcula Precisión (Accuracy), Sensibilidad (Recall) y Especificidad.\"\"\"\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Se extraen TP, FP, TN, FN de la Matriz de Confusión para calcular Especificidad\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "    # Especificidad = TN / (TN + FP)\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "    return f\"{accuracy * 100:.2f}%\", f\"{recall * 100:.2f}%\", f\"{specificity * 100:.2f}%\"\n",
        "\n",
        "print(\"Función 'calculate_metrics' definida.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDmWlGaoY5Sk",
        "outputId": "50e9ec98-79c9-4d74-b5f9-710b0b5bb844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Random Forest Final...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4202372472.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "/tmp/ipython-input-4202372472.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(df[col].median(), inplace=True)\n",
            "/tmp/ipython-input-4202372472.py:22: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[col].fillna(df[col].mode()[0], inplace=True)\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
            "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
            "  T = new_sum / new_sample_count\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
            "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Red Neuronal Final...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenamiento completado.\n"
          ]
        }
      ],
      "source": [
        "# --- 1. CONFIGURACIÓN INICIAL Y PREPROCESAMIENTO ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC # Importado en el notebook original\n",
        "\n",
        "# Carga de datos (ajusta la ruta si es necesario)\n",
        "df = pd.read_csv('/content/drive/MyDrive/IAProyecto/heart_disease_uci.csv')\n",
        "\n",
        "# Preprocesamiento robusto (similar al Paso 2 de tu notebook)\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.drop(columns=['id', 'dataset'], inplace=True)\n",
        "\n",
        "for col in ['ca', 'thal']:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == object or col in ['cp', 'restecg', 'slope']:\n",
        "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "    elif df[col].isnull().any():\n",
        "        df[col].fillna(df[col].median(), inplace=True)\n",
        "\n",
        "# Conversión de Target a Binario y Codificación One-Hot\n",
        "df['target'] = df['num'].apply(lambda x: 1 if x > 0 else 0)\n",
        "df.drop(columns=['num'], inplace=True)\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "\n",
        "y = df['target']\n",
        "X = df.drop(columns=['target'])\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "# División y Estandarización (Paso 3)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
        "\n",
        "# --- 2. ENTRENAMIENTO DE MODELOS FINALES (RF y DL) ---\n",
        "# Random Forest (Corregido: min_samples_leaf=5)\n",
        "print(\"Entrenando Random Forest Final...\")\n",
        "rf_model_final = RandomForestClassifier(\n",
        "    n_estimators=100, max_depth=5, min_samples_leaf=5, random_state=42\n",
        ")\n",
        "rf_model_final.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Red Neuronal Profunda (Corregida: con Dropout)\n",
        "print(\"Entrenando Red Neuronal Final...\")\n",
        "input_dim = X_train_scaled.shape[1]\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "nn_model_final = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu', input_shape=(input_dim,)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "nn_model_final.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "nn_model_final.fit(X_train_scaled, y_train, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "print(\"Entrenamiento completado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmmNjdy-YzLl",
        "outputId": "983a7612-208e-4989-ba5b-237903e934d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Métricas calculadas para los 4 escenarios (2 modelos x 2 datasets).\n"
          ]
        }
      ],
      "source": [
        "# Predicciones Random Forest\n",
        "y_pred_train_rf = rf_model_final.predict(X_train_scaled)\n",
        "y_pred_test_rf = rf_model_final.predict(X_test_scaled)\n",
        "\n",
        "# Predicciones Red Neuronal\n",
        "y_pred_train_nn_prob = nn_model_final.predict(X_train_scaled, verbose=0)\n",
        "y_pred_test_nn_prob = nn_model_final.predict(X_test_scaled, verbose=0)\n",
        "\n",
        "# Convertir probabilidades (Red Neuronal) a clases (0 o 1)\n",
        "y_pred_train_nn = (y_pred_train_nn_prob > 0.5).astype(int).flatten()\n",
        "y_pred_test_nn = (y_pred_test_nn_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "# Calcular métricas para la tabla\n",
        "rf_train_metrics = calculate_metrics(y_train, y_pred_train_rf)\n",
        "rf_test_metrics = calculate_metrics(y_test, y_pred_test_rf)\n",
        "nn_train_metrics = calculate_metrics(y_train, y_pred_train_nn)\n",
        "nn_test_metrics = calculate_metrics(y_test, y_pred_test_nn)\n",
        "\n",
        "print(\"Métricas calculadas para los 4 escenarios (2 modelos x 2 datasets).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lo3UqXRXZXrU",
        "outputId": "de9ddc1c-d30e-453c-96a1-8a485bb7b898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- TABLA DE RESULTADOS DEFINITIVA (EVALUACIÓN) ---\n",
            "| Métrica                     | RF Final (Entrenamiento)   | RF Final (Prueba)   | Red Neuronal Final (Entrenamiento)   | Red Neuronal Final (Prueba)   |\n",
            "|:----------------------------|:---------------------------|:--------------------|:-------------------------------------|:------------------------------|\n",
            "| Precisión (Accuracy)        | 86.96%                     | 80.43%              | 44.72%                               | 44.57%                        |\n",
            "| Sensibilidad (Recall)       | 91.85%                     | 83.66%              | 0.00%                                | 0.00%                         |\n",
            "| Especificidad (Specificity) | 80.90%                     | 76.42%              | 100.00%                              | 100.00%                       |\n"
          ]
        }
      ],
      "source": [
        "metrics = [\"Precisión (Accuracy)\", \"Sensibilidad (Recall)\", \"Especificidad (Specificity)\"]\n",
        "\n",
        "results = {\n",
        "    \"Métrica\": metrics,\n",
        "    \"RF Final (Entrenamiento)\": rf_train_metrics,\n",
        "    \"RF Final (Prueba)\": rf_test_metrics,\n",
        "    \"Red Neuronal Final (Entrenamiento)\": nn_train_metrics,\n",
        "    \"Red Neuronal Final (Prueba)\": nn_test_metrics\n",
        "}\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Mostrar la tabla en formato Markdown\n",
        "print(\"\\n--- TABLA DE RESULTADOS DEFINITIVA (EVALUACIÓN) ---\")\n",
        "print(df_results.to_markdown(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwHEzvpec6es",
        "outputId": "08adb435-00e8-4e4c-92ab-20908db44db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- INFERENCIA CON INTERPRETACIÓN CLÍNICA (FASE 7) ---\n",
            "|   ID |   Clase (0: Sano / 1: Enfermo) | Probabilidad Clase 1   | Nivel de Riesgo (Interpretación)         | Justificación Clínica                                                                                                   |\n",
            "|-----:|-------------------------------:|:-----------------------|:-----------------------------------------|:------------------------------------------------------------------------------------------------------------------------|\n",
            "|    1 |                              1 | 81.01%                 | ALTO RIESGO (Acción Clínica Recomendada) | La probabilidad supera el 70%, indicando un patrón clínico severo y consistente con la enfermedad.                      |\n",
            "|    2 |                              0 | 28.61%                 | BAJO RIESGO (Control Anual)              | La probabilidad es baja, el perfil clínico es mayoritariamente compatible con un paciente sano.                         |\n",
            "|    3 |                              0 | 48.76%                 | RIESGO MODERADO (Seguimiento Cercano)    | La probabilidad está cerca del 50%, lo que sugiere que el paciente tiene factores de riesgo que deben ser monitoreados. |\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def predict_and_interpret_patient(model, scaler, feature_columns, raw_data):\n",
        "    df_new = pd.DataFrame([raw_data])\n",
        "    df_pred = pd.get_dummies(df_new, drop_first=True)\n",
        "    df_pred = df_pred.reindex(columns=feature_columns, fill_value=0)\n",
        "    data_scaled = scaler.transform(df_pred)\n",
        "    df_scaled = pd.DataFrame(data_scaled, columns=feature_columns)\n",
        "    pred_class = model.predict(df_scaled)[0]\n",
        "    pred_prob = model.predict_proba(df_scaled)[0, 1]\n",
        "    if pred_prob >= 0.70:\n",
        "        interpretacion = \"ALTO RIESGO (Acción Clínica Recomendada)\"\n",
        "        justificacion = \"La probabilidad supera el 70%, indicando un patrón clínico severo y consistente con la enfermedad.\"\n",
        "    elif pred_prob >= 0.50:\n",
        "        interpretacion = \"RIESGO SIGNIFICATIVO (Monitoreo Urgente)\"\n",
        "        justificacion = \"La probabilidad es alta, requiriendo validación médica inmediata. El modelo está muy cerca del umbral de clasificación.\"\n",
        "    elif pred_prob >= 0.40:\n",
        "        interpretacion = \"RIESGO MODERADO (Seguimiento Cercano)\"\n",
        "        justificacion = \"La probabilidad está cerca del 50%, lo que sugiere que el paciente tiene factores de riesgo que deben ser monitoreados.\"\n",
        "    else:\n",
        "        interpretacion = \"BAJO RIESGO (Control Anual)\"\n",
        "        justificacion = \"La probabilidad es baja, el perfil clínico es mayoritariamente compatible con un paciente sano.\"\n",
        "\n",
        "    return int(pred_class), f\"{pred_prob * 100:.2f}%\", interpretacion, justificacion\n",
        "list_new_patients_raw = [\n",
        "    {\n",
        "        'age': 65, 'sex': 1, 'cp': 3, 'trestbps': 150, 'chol': 250, 'fbs': 1,\n",
        "        'restecg': 0, 'thalach': 120, 'exang': 1, 'oldpeak': 3.0, 'slope': 0,\n",
        "        'ca': 2, 'thal': 7\n",
        "    },\n",
        "    {\n",
        "        'age': 35, 'sex': 0, 'cp': 0, 'trestbps': 110, 'chol': 180, 'fbs': 0,\n",
        "        'restecg': 1, 'thalach': 180, 'exang': 0, 'oldpeak': 0.0, 'slope': 2,\n",
        "        'ca': 0, 'thal': 3\n",
        "    },\n",
        "    {\n",
        "        'age': 55, 'sex': 1, 'cp': 1, 'trestbps': 130, 'chol': 220, 'fbs': 0,\n",
        "        'restecg': 0, 'thalach': 150, 'exang': 0, 'oldpeak': 1.0, 'slope': 1,\n",
        "        'ca': 1, 'thal': 6\n",
        "    }\n",
        "]\n",
        "results = []\n",
        "feature_columns = X.columns.tolist()\n",
        "for i, patient_data in enumerate(list_new_patients_raw):\n",
        "    pred_class, pred_prob_pct, interpretacion, justificacion = predict_and_interpret_patient(\n",
        "        rf_model_final, scaler, feature_columns, patient_data\n",
        "    )\n",
        "    results.append({\n",
        "        'ID': i + 1,\n",
        "        'Clase (0: Sano / 1: Enfermo)': pred_class,\n",
        "        'Probabilidad Clase 1': pred_prob_pct,\n",
        "        'Nivel de Riesgo (Interpretación)': interpretacion,\n",
        "        'Justificación Clínica': justificacion\n",
        "    })\n",
        "df_interpretacion_final = pd.DataFrame(results)\n",
        "print(\"\\n--- INFERENCIA CON INTERPRETACIÓN CLÍNICA (FASE 7) ---\")\n",
        "print(df_interpretacion_final.to_markdown(index=False))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}